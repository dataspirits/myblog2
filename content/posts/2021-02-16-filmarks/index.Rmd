---
title: 'filmarksの映画レビューをスクレイピング'
author: 'naruse'
date: '2021-02-16'
slug: []
categories:
  - R
tags:
  - scraping
---

映画レビューサイトのFilmarksというサイトから、ユーザーの平均スコアをスクレイピングしてみた。

まずは簡単にrvestパッケージを利用して映画タイトルと平均スコアのみを取得する。


```{r library, message=FALSE}

#パッケージの読み込み
library(tidyverse)
library(rvest)

#結果を入れるハコ
data <- data.frame()

```


対象は製作年が2020年の全作品とする。コロナであんまり映画館行けなかったので、普通にいい評価の作品を知りたい。

平均スコアを取得するだけならかなり単純で、for文でurlのページをぐるぐる回しつつ`read_html()`関数で取得すればよい。

うまく書く場合はループ数を指定しなくてもいいと思うが面倒くさいので101ページということを目で確認して記入した。

```{r scraping, eval=FALSE}

#繰り返し数は指定
for(i in 1:101){
  
  #2020年製作の映画のurl
  fil_url <- paste0("https://filmarks.com/list/year/2020s/2020?page=",i)
  
  #htmlを取得
  url_res <- read_html(fil_url)
  
  #html要素内のタイトルをcssセレクタで指定
  title <- url_res %>% 
    html_nodes(css = ".p-content-cassette__title") %>% 
    html_text()

  #html要素内のスコアをXPathで指定
  score <- url_res %>% 
    html_nodes(xpath = "//div[@class = 'p-content-cassette__info']//div[@class = 'c-rating__score']") %>% 
    html_text()
  
  #データフレームにする
  temp <- data.frame(title=title,score=score)
  
  #ハコに順次格納
  data <- bind_rows(data,temp)
  
  #1秒待つ
  Sys.sleep(1)

}

```


```{r, include=FALSE}
#上は実行せずに取得済みを取得
data <- read_csv(file = "filmarks.csv")
```


取得したデータは文字列だったりするので加工が必要。

平均スコアがない作品は"-"となっているので対象から外してヒストグラムを見てみる。

```{r visualize}

#"-"のデータを消去と数値に変換
target <- data %>% 
  filter(score != "-") %>% 
  mutate(score = as.numeric(score))

#可視化
p1 <- ggplot(target, aes(x = score))
p1 + geom_histogram(breaks = seq(0,5,0.1))


```

やっぱ真ん中っぽい3.5が多いんですね。あとは1.0,2.0,3.0,4.0,5.0が周辺に比べて多いのと3.1、3.3、...といった奇数/10より3.2、3.4、...といった偶数/10のほうが若干多いように見える。


上位作品を確認。レビュー数が少ないものが上位にくるのでこのままではダメ。

```{r ranking}

#scoreを降順にする
ranking <- target %>% 
  arrange(desc(score)) 

ranking %>% 
  as_tibble()

```

一旦ここまで。
